{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":2222626,"sourceType":"datasetVersion","datasetId":1322457},{"sourceId":173877636,"sourceType":"kernelVersion"}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader\nfrom torchvision import transforms\nfrom torchvision.datasets import ImageFolder\nfrom torchvision.utils import save_image\nfrom tqdm import tqdm\nimport itertools","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-04-26T15:40:56.162866Z","iopub.execute_input":"2024-04-26T15:40:56.163292Z","iopub.status.idle":"2024-04-26T15:41:02.445152Z","shell.execute_reply.started":"2024-04-26T15:40:56.163260Z","shell.execute_reply":"2024-04-26T15:41:02.444128Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass AttentionGate(nn.Module):\n    def __init__(self, F_g, F_l, F_int):\n        super(AttentionGate, self).__init__()\n        self.W_g = nn.Conv2d(F_g, F_int, kernel_size=1, stride=1, padding=0, bias=True)\n        self.W_x = nn.Conv2d(F_l, F_int, kernel_size=1, stride=1, padding=0, bias=True)\n        \n        self.psi = nn.Sequential(\n            nn.Conv2d(F_int, 1, kernel_size=1, stride=1, padding=0, bias=True),\n            nn.Sigmoid()\n        )\n        \n        self.relu = nn.ReLU(inplace=True)\n\n    def forward(self, g, x):\n        g1 = self.W_g(g)\n        x1 = self.W_x(x)\n        psi = self.relu(g1 + x1)\n        psi = self.psi(psi)\n        return x * psi","metadata":{"execution":{"iopub.status.busy":"2024-04-26T15:41:02.447163Z","iopub.execute_input":"2024-04-26T15:41:02.447541Z","iopub.status.idle":"2024-04-26T15:41:02.456771Z","shell.execute_reply.started":"2024-04-26T15:41:02.447516Z","shell.execute_reply":"2024-04-26T15:41:02.455831Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"class Generator(nn.Module):\n    def __init__(self):\n        super(Generator, self).__init__()\n        # Downsample\n        self.downsample = nn.Sequential(\n            nn.Conv2d(3, 32, kernel_size=4, stride=2, padding=1),\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Conv2d(32, 64, kernel_size=4, stride=2, padding=1),\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1),\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1),\n            nn.LeakyReLU(0.2, inplace=True),\n        )\n        # Upsample\n        self.upsample = nn.Sequential(\n            nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1),\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1),\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.ConvTranspose2d(64, 32, kernel_size=4, stride=2, padding=1),\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.ConvTranspose2d(32, 3, kernel_size=4, stride=2, padding=1),\n            nn.Tanh()\n        )\n        \n        # Attention Gates\n        self.att1 = AttentionGate(F_g=128, F_l=128, F_int=64)\n        self.att2 = AttentionGate(F_g=64, F_l=64, F_int=32)\n        self.att3 = AttentionGate(F_g=32, F_l=32, F_int=16)\n\n    def forward(self, x):\n        # Encoder\n        d1 = self.downsample[0:2](x) # 32\n        d2 = self.downsample[2:4](d1) # 64\n        d3 = self.downsample[4:6](d2) # 128\n        d4 = self.downsample[6:8](d3) # 256\n        \n        # Decoder with attention\n        u3 = self.upsample[0:2](d4) \n        u3 = self.att1(g=u3, x=d3)\n        u2 = self.upsample[2:4](u3) \n        u2 = self.att2(g=u2, x=d2)\n        u1 = self.upsample[4:6](u2)\n        out = self.upsample[6:8](u1)\n        \n        return out\n","metadata":{"execution":{"iopub.status.busy":"2024-04-26T15:41:02.461302Z","iopub.execute_input":"2024-04-26T15:41:02.461551Z","iopub.status.idle":"2024-04-26T15:41:02.480743Z","shell.execute_reply.started":"2024-04-26T15:41:02.461529Z","shell.execute_reply":"2024-04-26T15:41:02.479880Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"import torch.nn as nn\n\nclass Discriminator(nn.Module):\n    def __init__(self):\n        super(Discriminator, self).__init__()\n        self.model = nn.Sequential(\n            nn.Conv2d(3, 128, kernel_size=3, stride=1, padding=1),\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1),\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Conv2d(512, 1, kernel_size=3, stride=1, padding=1),  # Output a single scalar\n            nn.Sigmoid()  # Output in [0, 1] range (for binary classification)\n        )\n\n    def forward(self, x):\n        return self.model(x)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-26T15:41:02.483894Z","iopub.execute_input":"2024-04-26T15:41:02.484717Z","iopub.status.idle":"2024-04-26T15:41:02.495517Z","shell.execute_reply.started":"2024-04-26T15:41:02.484688Z","shell.execute_reply":"2024-04-26T15:41:02.494581Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"!ls ../input/Dataset/images","metadata":{"execution":{"iopub.status.busy":"2024-04-26T15:41:02.496457Z","iopub.execute_input":"2024-04-26T15:41:02.496699Z","iopub.status.idle":"2024-04-26T15:41:03.457860Z","shell.execute_reply.started":"2024-04-26T15:41:02.496678Z","shell.execute_reply":"2024-04-26T15:41:03.456706Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"ls: cannot access '../input/Dataset/images': No such file or directory\n","output_type":"stream"}]},{"cell_type":"code","source":"# Define transformations for data preprocessing\ntransform = transforms.Compose([\n    transforms.Resize((256, 256)),  # Resize images to a consistent size\n    transforms.Grayscale(),          # Convert images to grayscale\n    transforms.ToTensor(),           # Convert images to PyTorch tensors\n    transforms.Normalize((0.5,), (0.5,))  # Normalize images to the range [-1, 1]\n])\n\n\n","metadata":{"execution":{"iopub.status.busy":"2024-04-26T15:41:03.459413Z","iopub.execute_input":"2024-04-26T15:41:03.459722Z","iopub.status.idle":"2024-04-26T15:41:03.465897Z","shell.execute_reply.started":"2024-04-26T15:41:03.459693Z","shell.execute_reply":"2024-04-26T15:41:03.464894Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"\n# Initialize hyperparameters\nbatch_size = 4\nlearning_rate = 0.0002\nnum_epochs = 3\nlambda_cycle = 10  # Weight for cycle consistency loss\n\n","metadata":{"execution":{"iopub.status.busy":"2024-04-26T15:41:03.467200Z","iopub.execute_input":"2024-04-26T15:41:03.467545Z","iopub.status.idle":"2024-04-26T15:41:03.475756Z","shell.execute_reply.started":"2024-04-26T15:41:03.467522Z","shell.execute_reply":"2024-04-26T15:41:03.474901Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"import os\nimport cv2\nimport numpy as np\nfrom torch.utils.data import Dataset\nfrom torchvision.transforms import ToTensor\n\nclass CustomImageDataset(Dataset):\n    def __init__(self, root_dir, transform=None):\n        self.root_dir = root_dir\n        self.transform = transform\n        self.image_paths = self._load_image_paths()\n\n    def __len__(self):\n        return len(self.image_paths)\n\n    def __getitem__(self, idx):\n        img_path = self.image_paths[idx]\n        img = self._read_image(img_path)\n\n        if self.transform:\n            img = self.transform(img)\n\n        return img\n\n    def _load_image_paths(self):\n        image_paths = []\n        for root, _, files in os.walk(self.root_dir):\n            for file in files:\n                if file.endswith('.jpg') or file.endswith('.png'):\n                    image_paths.append(os.path.join(root, file))\n        return image_paths\n\n    def _read_image(self, img_path):\n        img = cv2.imread(img_path)\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        img = cv2.resize(img, (256, 256))\n        img = img.astype(np.float32) / 255.0  # Convert to float32 and normalize to range [0, 1]\n        return img\n\n\ndata_dir = \"/kaggle/input/ct-to-mri-cgan/Dataset/images\"\ntransform = ToTensor()  # Convert images to PyTorch tensors\n\n# Create custom datasets\ntrain_dataset_A = CustomImageDataset(root_dir=os.path.join(data_dir, 'trainA'), transform=transform)\ntrain_dataset_B = CustomImageDataset(root_dir=os.path.join(data_dir, 'trainB'), transform=transform)\ntest_dataset_A = CustomImageDataset(root_dir=os.path.join(data_dir, 'testA'), transform=transform)\ntest_dataset_B = CustomImageDataset(root_dir=os.path.join(data_dir, 'testB'), transform=transform)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-26T15:41:03.479391Z","iopub.execute_input":"2024-04-26T15:41:03.479670Z","iopub.status.idle":"2024-04-26T15:41:11.433224Z","shell.execute_reply.started":"2024-04-26T15:41:03.479648Z","shell.execute_reply":"2024-04-26T15:41:11.432418Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"!ls \"/kaggle/input/ct-to-mri-cgan/Dataset/images\"","metadata":{"execution":{"iopub.status.busy":"2024-04-26T15:41:11.434267Z","iopub.execute_input":"2024-04-26T15:41:11.434555Z","iopub.status.idle":"2024-04-26T15:41:12.378695Z","shell.execute_reply.started":"2024-04-26T15:41:11.434531Z","shell.execute_reply":"2024-04-26T15:41:12.377750Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"testA  testB  trainA  trainB\n","output_type":"stream"}]},{"cell_type":"code","source":"print(\"Length of train_dataset_A:\", len(train_dataset_A))\nprint(\"Length of train_dataset_B:\", len(train_dataset_B))\nprint(\"Length of test_dataset_A:\", len(test_dataset_A))\nprint(\"Length of test_dataset_B:\", len(test_dataset_B))\n","metadata":{"execution":{"iopub.status.busy":"2024-04-26T15:41:12.380061Z","iopub.execute_input":"2024-04-26T15:41:12.380325Z","iopub.status.idle":"2024-04-26T15:41:12.386657Z","shell.execute_reply.started":"2024-04-26T15:41:12.380297Z","shell.execute_reply":"2024-04-26T15:41:12.385724Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Length of train_dataset_A: 1742\nLength of train_dataset_B: 1744\nLength of test_dataset_A: 744\nLength of test_dataset_B: 744\n","output_type":"stream"}]},{"cell_type":"code","source":"# Define data loaders\ntrain_loader_A = DataLoader(dataset=train_dataset_A, batch_size=batch_size, shuffle=True)\ntrain_loader_B = DataLoader(dataset=train_dataset_B, batch_size=batch_size, shuffle=True)\ntest_loader_A = DataLoader(dataset=test_dataset_A, batch_size=batch_size, shuffle=False)\ntest_loader_B = DataLoader(dataset=test_dataset_B, batch_size=batch_size, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2024-04-26T15:41:12.387764Z","iopub.execute_input":"2024-04-26T15:41:12.388059Z","iopub.status.idle":"2024-04-26T15:41:12.398780Z","shell.execute_reply.started":"2024-04-26T15:41:12.388037Z","shell.execute_reply":"2024-04-26T15:41:12.397933Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# Initialize generator and discriminator\nG_AB = Generator()\nG_BA = Generator()\nD_A = Discriminator()\nD_B = Discriminator()","metadata":{"execution":{"iopub.status.busy":"2024-04-26T15:41:12.400030Z","iopub.execute_input":"2024-04-26T15:41:12.400459Z","iopub.status.idle":"2024-04-26T15:41:12.499322Z","shell.execute_reply.started":"2024-04-26T15:41:12.400428Z","shell.execute_reply":"2024-04-26T15:41:12.498367Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# Print Generator model structure\nprint(\"Generator Model:\")\nprint(G_AB)\n\n# Print Discriminator model structure\nprint(\"\\nDiscriminator Model:\")\nprint(D_A)","metadata":{"execution":{"iopub.status.busy":"2024-04-26T15:41:12.502877Z","iopub.execute_input":"2024-04-26T15:41:12.503168Z","iopub.status.idle":"2024-04-26T15:41:12.508654Z","shell.execute_reply.started":"2024-04-26T15:41:12.503144Z","shell.execute_reply":"2024-04-26T15:41:12.507674Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Generator Model:\nGenerator(\n  (downsample): Sequential(\n    (0): Conv2d(3, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n    (2): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n    (3): LeakyReLU(negative_slope=0.2, inplace=True)\n    (4): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n    (5): LeakyReLU(negative_slope=0.2, inplace=True)\n    (6): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n    (7): LeakyReLU(negative_slope=0.2, inplace=True)\n  )\n  (upsample): Sequential(\n    (0): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n    (2): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n    (3): LeakyReLU(negative_slope=0.2, inplace=True)\n    (4): ConvTranspose2d(64, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n    (5): LeakyReLU(negative_slope=0.2, inplace=True)\n    (6): ConvTranspose2d(32, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n    (7): Tanh()\n  )\n  (att1): AttentionGate(\n    (W_g): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n    (W_x): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n    (psi): Sequential(\n      (0): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))\n      (1): Sigmoid()\n    )\n    (relu): ReLU(inplace=True)\n  )\n  (att2): AttentionGate(\n    (W_g): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n    (W_x): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n    (psi): Sequential(\n      (0): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))\n      (1): Sigmoid()\n    )\n    (relu): ReLU(inplace=True)\n  )\n  (att3): AttentionGate(\n    (W_g): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n    (W_x): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n    (psi): Sequential(\n      (0): Conv2d(16, 1, kernel_size=(1, 1), stride=(1, 1))\n      (1): Sigmoid()\n    )\n    (relu): ReLU(inplace=True)\n  )\n)\n\nDiscriminator Model:\nDiscriminator(\n  (model): Sequential(\n    (0): Conv2d(3, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n    (2): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (3): LeakyReLU(negative_slope=0.2, inplace=True)\n    (4): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (5): LeakyReLU(negative_slope=0.2, inplace=True)\n    (6): Conv2d(512, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (7): Sigmoid()\n  )\n)\n","output_type":"stream"}]},{"cell_type":"code","source":"# Define loss functions\ncriterion_GAN = nn.MSELoss()\ncriterion_cycle = nn.L1Loss()","metadata":{"execution":{"iopub.status.busy":"2024-04-26T15:41:12.509831Z","iopub.execute_input":"2024-04-26T15:41:12.510169Z","iopub.status.idle":"2024-04-26T15:41:12.519821Z","shell.execute_reply.started":"2024-04-26T15:41:12.510139Z","shell.execute_reply":"2024-04-26T15:41:12.518972Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# Initialize optimizers\noptimizer_G = optim.AdamW(itertools.chain(G_AB.parameters(), G_BA.parameters()), lr=learning_rate)\noptimizer_D_A = optim.AdamW(D_A.parameters(), lr=learning_rate)\noptimizer_D_B = optim.AdamW(D_B.parameters(), lr=learning_rate)","metadata":{"execution":{"iopub.status.busy":"2024-04-26T15:41:12.521009Z","iopub.execute_input":"2024-04-26T15:41:12.521292Z","iopub.status.idle":"2024-04-26T15:41:12.531154Z","shell.execute_reply.started":"2024-04-26T15:41:12.521270Z","shell.execute_reply":"2024-04-26T15:41:12.530393Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"import os\n\n# Define the directory to save images\noutput_dir = '/kaggle/working/output_images'\nos.makedirs(output_dir, exist_ok=True)  # Create the directory if it doesn't exist\n\n","metadata":{"execution":{"iopub.status.busy":"2024-04-26T15:41:12.532148Z","iopub.execute_input":"2024-04-26T15:41:12.532424Z","iopub.status.idle":"2024-04-26T15:41:12.540902Z","shell.execute_reply.started":"2024-04-26T15:41:12.532401Z","shell.execute_reply":"2024-04-26T15:41:12.540142Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# Move the generator and discriminator models to the selected device\nG_AB.to(device)\nG_BA.to(device)\nD_A.to(device)\nD_B.to(device)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-26T15:41:12.541977Z","iopub.execute_input":"2024-04-26T15:41:12.543078Z","iopub.status.idle":"2024-04-26T15:41:12.736944Z","shell.execute_reply.started":"2024-04-26T15:41:12.543053Z","shell.execute_reply":"2024-04-26T15:41:12.736057Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"Discriminator(\n  (model): Sequential(\n    (0): Conv2d(3, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n    (2): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (3): LeakyReLU(negative_slope=0.2, inplace=True)\n    (4): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (5): LeakyReLU(negative_slope=0.2, inplace=True)\n    (6): Conv2d(512, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (7): Sigmoid()\n  )\n)"},"metadata":{}}]},{"cell_type":"code","source":"import os\nimport torch\nimport pickle\n# Define paths for saving model weights and entire models\nmodel_dir = '/kaggle/working/saved_models'\nos.makedirs(model_dir, exist_ok=True)\n\n\n# Define paths for saving model weights and entire models\nmodel_dir = '/kaggle/working/saved_models'\nos.makedirs(model_dir, exist_ok=True)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-26T15:41:12.738201Z","iopub.execute_input":"2024-04-26T15:41:12.738552Z","iopub.status.idle":"2024-04-26T15:41:12.744761Z","shell.execute_reply.started":"2024-04-26T15:41:12.738520Z","shell.execute_reply":"2024-04-26T15:41:12.743916Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"from tqdm.auto import tqdm","metadata":{"execution":{"iopub.status.busy":"2024-04-26T15:41:12.745946Z","iopub.execute_input":"2024-04-26T15:41:12.746258Z","iopub.status.idle":"2024-04-26T15:41:12.754539Z","shell.execute_reply.started":"2024-04-26T15:41:12.746229Z","shell.execute_reply":"2024-04-26T15:41:12.753699Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"# Initialize the best loss with a high value\nbest_loss = float('inf')\nimport os\n\n# Open a log file in write mode\nwith open(os.path.join(model_dir, '/kaggle/working/training_log.txt'), 'w') as log_file:\n    for epoch in range(num_epochs):\n        epoch_loss = 0  # Initialize loss accumulator for the epoch\n\n        for i, (real_A, real_B) in enumerate(zip(train_loader_A, train_loader_B)):\n            real_A = real_A.to(device)\n            real_B = real_B.to(device)\n\n            # -------------------\n            #  Train Generators\n            # -------------------\n            fake_B = G_AB(real_A)\n            rec_A = G_BA(fake_B)\n            fake_A = G_BA(real_B)\n            rec_B = G_AB(fake_A)\n\n            # Generator losses\n            loss_GAN_AB = criterion_GAN(D_B(fake_B), torch.ones_like(D_B(fake_B)))\n            loss_GAN_BA = criterion_GAN(D_A(fake_A), torch.ones_like(D_A(fake_A)))\n            loss_cycle_A = criterion_cycle(rec_A, real_A)\n            loss_cycle_B = criterion_cycle(rec_B, real_B)\n            \n            # Total generator loss\n            loss_G = loss_GAN_AB + loss_GAN_BA + lambda_cycle * (loss_cycle_A + loss_cycle_B)\n\n            # Backward and optimize\n            optimizer_G.zero_grad()\n            loss_G.backward()\n            optimizer_G.step()\n\n            # ---------------------\n            #  Train Discriminators\n            # ---------------------\n            loss_D_A_real = criterion_GAN(D_A(real_A), torch.ones_like(D_A(real_A)))\n            loss_D_A_fake = criterion_GAN(D_A(fake_A.detach()), torch.zeros_like(D_A(fake_A)))\n            loss_D_A = (loss_D_A_real + loss_D_A_fake) / 2\n\n            loss_D_B_real = criterion_GAN(D_B(real_B), torch.ones_like(D_B(real_B)))\n            loss_D_B_fake = criterion_GAN(D_B(fake_B.detach()), torch.zeros_like(D_B(fake_B)))\n            loss_D_B = (loss_D_B_real + loss_D_B_fake) / 2\n\n            optimizer_D_A.zero_grad()\n            optimizer_D_B.zero_grad()\n            loss_D_A.backward()\n            loss_D_B.backward()\n            optimizer_D_A.step()\n            optimizer_D_B.step()\n\n            # Accumulate losses for the epoch\n            epoch_loss += loss_G.item() + loss_D_A.item() + loss_D_B.item()\n\n        # Average the loss over the number of batches\n        epoch_loss /= len(train_loader_A)\n\n        # Check if this epoch's loss is the best; if yes, save the model\n        if epoch_loss < best_loss:\n            best_loss = epoch_loss\n            torch.save(G_AB.state_dict(), os.path.join(model_dir, 'best_generator_AB_weights.pth'))\n            torch.save(G_BA.state_dict(), os.path.join(model_dir, 'best_generator_BA_weights.pth'))\n            torch.save(D_A.state_dict(), os.path.join(model_dir, 'best_discriminator_A_weights.pth'))\n            torch.save(D_B.state_dict(), os.path.join(model_dir, 'best_discriminator_B_weights.pth'))\n            log_file.write(f'Epoch [{epoch+1}/{num_epochs}], New best average loss: {best_loss}, Models saved!\\n')\n\n        # Periodic logging and image saving (every 5 epochs)\n        if epoch % 5 == 0:\n            save_image(fake_B, os.path.join(output_dir, f'fake_B_{epoch}.png'))\n            save_image(fake_A, os.path.join(output_dir, f'fake_A_{epoch}.png'))\n            log_file.write(f\"Epoch [{epoch+1}/{num_epochs}], Generator Loss: {loss_G.item()}, Discriminator A Loss: {loss_D_A.item()}, Discriminator B Loss: {loss_D_B.item()}, GAN Loss AB: {loss_GAN_AB.item()}, GAN Loss BA: {loss_GAN_BA.item()}, Cycle Loss A: {loss_cycle_A.item()}, Cycle Loss B: {loss_cycle_B.item()}\\n\")\n\n    log_file.write(\"Training completed!\\n\")\n","metadata":{"execution":{"iopub.status.busy":"2024-04-26T17:08:13.007119Z","iopub.execute_input":"2024-04-26T17:08:13.007389Z","iopub.status.idle":"2024-04-26T17:13:04.684023Z","shell.execute_reply.started":"2024-04-26T17:08:13.007367Z","shell.execute_reply":"2024-04-26T17:13:04.682873Z"},"trusted":true},"execution_count":24,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[24], line 55\u001b[0m\n\u001b[1;32m     52\u001b[0m     optimizer_D_B\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;66;03m# Accumulate losses for the epoch\u001b[39;00m\n\u001b[0;32m---> 55\u001b[0m     epoch_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss_G\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m+\u001b[39m loss_D_A\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;241m+\u001b[39m loss_D_B\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# Average the loss over the number of batches\u001b[39;00m\n\u001b[1;32m     58\u001b[0m epoch_loss \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(train_loader_A)\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"import os\nimport torch\nimport pickle\n\n# Define paths for saving model weights and entire models\nmodel_dir = 'saved_models'\nos.makedirs(model_dir, exist_ok=True)\n\n\n# Define file paths for saving the state dicts\ngenerator_AB_weights_path = os.path.join(model_dir, 'generator_AB_weights.pth')\ngenerator_BA_weights_path = os.path.join(model_dir, 'generator_BA_weights.pth')\ndiscriminator_A_weights_path = os.path.join(model_dir, 'discriminator_A_weights.pth')\ndiscriminator_B_weights_path = os.path.join(model_dir, 'discriminator_B_weights.pth')\n\n# Define file paths for saving the entire models (for pickling)\ngenerator_AB_model_path = os.path.join(model_dir, 'generator_AB_model.pkl')\ngenerator_BA_model_path = os.path.join(model_dir, 'generator_BA_model.pkl')\ndiscriminator_A_model_path = os.path.join(model_dir, 'discriminator_A_model.pkl')\ndiscriminator_B_model_path = os.path.join(model_dir, 'discriminator_B_model.pkl')\n\n# Training loop (omitted for brevity)\n\n# Save the model weights\ntorch.save(G_AB.state_dict(), generator_AB_weights_path)\ntorch.save(G_BA.state_dict(), generator_BA_weights_path)\ntorch.save(D_A.state_dict(), discriminator_A_weights_path)\ntorch.save(D_B.state_dict(), discriminator_B_weights_path)\n\n# Save the entire models using pickle\nwith open(generator_AB_model_path, 'wb') as f:\n    pickle.dump(G_AB, f)\n\nwith open(generator_BA_model_path, 'wb') as f:\n    pickle.dump(G_BA, f)\n\nwith open(discriminator_A_model_path, 'wb') as f:\n    pickle.dump(D_A, f)\n\nwith open(discriminator_B_model_path, 'wb') as f:\n    pickle.dump(D_B, f)\n\nprint(f\"Models and weights saved to {model_dir}:\")\nprint(f\"Generator AB weights -> {generator_AB_weights_path}\")\nprint(f\"Generator BA weights -> {generator_BA_weights_path}\")\nprint(f\"Discriminator A weights -> {discriminator_A_weights_path}\")\nprint(f\"Discriminator B weights -> {discriminator_B_weights_path}\")\nprint(f\"Generator AB model -> {generator_AB_model_path}\")\nprint(f\"Generator BA model -> {generator_BA_model_path}\")\nprint(f\"Discriminator A model -> {discriminator_A_model_path}\")\nprint(f\"Discriminator B model -> {discriminator_B_model_path}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-04-26T15:52:00.863250Z","iopub.status.idle":"2024-04-26T15:52:00.863603Z","shell.execute_reply.started":"2024-04-26T15:52:00.863442Z","shell.execute_reply":"2024-04-26T15:52:00.863456Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# Set generator models to evaluation mode\nG_AB.eval()\nG_BA.eval()\n\n# Test loop\nwith torch.no_grad():\n    for i, (real_A, real_B) in enumerate(zip(test_loader_A, test_loader_B)):\n        # Move real_A and real_B to the device\n        real_A = real_A.to(device)\n        real_B = real_B.to(device)\n\n        # Generate fake images\n        fake_B = G_AB(real_A[0].unsqueeze(0))  # Add batch dimension\n        fake_A = G_BA(real_B[0].unsqueeze(0))  # Add batch dimension\n\n        # Save and print generated images\n        save_image(fake_B, os.path.join(output_dir, f'test_fake_B_{i}.png'))\n        save_image(fake_A, os.path.join(output_dir, f'test_fake_A_{i}.png'))\n        \n        print(f\"Test Image {i}:\")\n        print(\"Real A:\")\n        plt.imshow(real_A[0].permute(1, 2, 0).cpu().numpy())\n        plt.show()\n        print(\"Real B:\")\n        plt.imshow(real_B[0].permute(1, 2, 0).cpu().numpy())\n        plt.show()\n        print(\"Generated B from A:\")\n        plt.imshow(fake_B[0].permute(1, 2, 0).cpu().numpy())\n        plt.show()\n        print(\"Generated A from B:\")\n        plt.imshow(fake_A[0].permute(1, 2, 0).cpu().numpy())\n        plt.show()\n\n        if i == 24:  # Stop after processing 25 images\n            break","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-04-26T15:52:00.864507Z","iopub.status.idle":"2024-04-26T15:52:00.864831Z","shell.execute_reply.started":"2024-04-26T15:52:00.864674Z","shell.execute_reply":"2024-04-26T15:52:00.864687Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\n# Initialize models with suffixes\nG_AB_new = Generator()\nG_BA_new = Generator()\nD_A_new = Discriminator()\nD_B_new = Discriminator()\n\n# Path to your saved model weights\nmodel_dir = '/kaggle/input/cyclegan100e/saved_models/'\n\n# Load the weights into the new model instances\nG_AB_new.load_state_dict(torch.load(os.path.join(model_dir, 'best_generator_AB_weights.pth')))\nG_BA_new.load_state_dict(torch.load(os.path.join(model_dir, 'best_generator_BA_weights.pth')))\nD_A_new.load_state_dict(torch.load(os.path.join(model_dir, 'best_discriminator_A_weights.pth')))\nD_B_new.load_state_dict(torch.load(os.path.join(model_dir, 'best_discriminator_B_weights.pth')))\n\n# Move models to GPU if CUDA is available\nif torch.cuda.is_available():\n    G_AB_new.cuda()\n    G_BA_new.cuda()\n    D_A_new.cuda()\n    D_B_new.cuda()\n\nprint(\"Models with new suffixes loaded successfully and ready for use!\")\n","metadata":{"execution":{"iopub.status.busy":"2024-04-26T15:52:00.866361Z","iopub.status.idle":"2024-04-26T15:52:00.866684Z","shell.execute_reply.started":"2024-04-26T15:52:00.866528Z","shell.execute_reply":"2024-04-26T15:52:00.866540Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt \ndef perform_inference(G_AB, G_BA, test_loader_A, test_loader_B, device, output_dir):\n    \"\"\"\n    Perform inference using provided generator models on test data.\n    Args:\n    - G_AB: Generator model from domain A to B.\n    - G_BA: Generator model from domain B to A.\n    - test_loader_A: DataLoader for domain A test images.\n    - test_loader_B: DataLoader for domain B test images.\n    - device: Device to run the inference on (e.g., 'cuda' or 'cpu').\n    - output_dir: Directory to save generated images.\n    \"\"\"\n    # Set generator models to evaluation mode\n    G_AB.eval()\n    G_BA.eval()\n\n    # Test loop with no gradients needed for inference\n    with torch.no_grad():\n        for i, (real_A, real_B) in enumerate(zip(test_loader_A, test_loader_B)):\n            # Move real_A and real_B to the device\n            real_A = real_A.to(device)\n            real_B = real_B.to(device)\n\n            # Generate fake images\n            fake_B = G_AB(real_A[0].unsqueeze(0))  # Add batch dimension\n            fake_A = G_BA(real_B[0].unsqueeze(0))  # Add batch dimension\n\n            # Save and print generated images\n            save_image(fake_B, os.path.join(output_dir, f'test_fake_B_{i}.png'))\n            save_image(fake_A, os.path.join(output_dir, f'test_fake_A_{i}.png'))\n            \n            print(f\"Test Image {i}:\")\n            print(\"Real A:\")\n            plt.imshow(real_A[0].permute(1, 2, 0).cpu().numpy())\n            plt.show()\n            print(\"Real B:\")\n            plt.imshow(real_B[0].permute(1, 2, 0).cpu().numpy())\n            plt.show()\n            print(\"Generated B from A:\")\n            plt.imshow(fake_B[0].permute(1, 2, 0).cpu().numpy())\n            plt.show()\n            print(\"Generated A from B:\")\n            plt.imshow(fake_A[0].permute(1, 2, 0).cpu().numpy())\n            plt.show()\n\n            if i == 24:  # Stop after processing 25 images\n                break\n\n# Example of how to call the function\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nimage_dir = '/kaggle/working/best_output_images'\nos.makedirs(image_dir, exist_ok=True)\nperform_inference(G_AB_new, G_BA_new, test_loader_A, test_loader_B, device, image_dir)","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-04-26T15:52:00.868209Z","iopub.status.idle":"2024-04-26T15:52:00.868528Z","shell.execute_reply.started":"2024-04-26T15:52:00.868374Z","shell.execute_reply":"2024-04-26T15:52:00.868386Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}